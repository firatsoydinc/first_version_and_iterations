{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db02f3ce",
   "metadata": {},
   "source": [
    "### Content-Based Recommendation System with Real Dataset\n",
    "\n",
    "Distance is an important variable since the process of borrowing books from the pop-up library is done physically. During the user testing with the online dataset, the participants thought that it was not helpful to recommend a book located far away. For this reason, it has been tried to make accessible recommendations to the user by adding the city restriction to the study.\n",
    "\n",
    "By determining the pop-up libraries in Utrecht, Netherlands as the pilot region for the study, a recommendation system was developed by using the books in these pop-up libraries.\n",
    "\n",
    "The data of the books in the pop-up libraries in Utrecht were obtained by web scraping using bookfinder.com over the ISBN number.\n",
    "\n",
    "The methods used in the recommendation system such as web scraper and geofinder are detailed in the file important_functions.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "403fdeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "import pgeocode\n",
    "import geopy.distance\n",
    "import geocoder\n",
    "\n",
    "from statistics import mode\n",
    "\n",
    "## To calculate cosine similarity among books \n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a89d91ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation_system():\n",
    "    user_name = input('Please enter your name:')\n",
    "    print('Welcome', user_name,'Do you want to share your current location with us to give you better recommendations?')\n",
    "    ## User's location sharing preferences\n",
    "    user_preferences_1 = input('Yes/No? ')\n",
    "    if ((user_preferences_1.lower() == 'yes')|(user_preferences_1.lower() == 'y')):\n",
    "        ##Accessing location data using IP address\n",
    "            geocode  = geocoder.ip('me')\n",
    "            latitude = geocode.latlng[0]\n",
    "            longitude= geocode.latlng[1]\n",
    "    else:\n",
    "        ##Accessing location data using postal code\n",
    "        nomi = pgeocode.Nominatim('nl')\n",
    "        postal_code = input('Please enter your current postal code')\n",
    "        postal_code= str(postal_code)\n",
    "        a = nomi.query_postal_code(postal_code)\n",
    "        a = a.to_frame().reset_index()\n",
    "        geo_codes = a[(a['index'] == 'latitude') | (a['index'] == 'longitude')]\n",
    "        geo_codes.reset_index(drop= True, inplace=True)\n",
    "        geo_codes=geo_codes.rename(columns={'index':'geotype',0:'geo_number'})\n",
    "        geo_codes[\"geo_number\"] = pd.to_numeric(geo_codes[\"geo_number\"], downcast=\"float\")\n",
    "        latitude = geo_codes[0:1]\n",
    "        longitude= geo_codes[1:2]\n",
    "        latitude =latitude['geo_number'][0]\n",
    "        longitude = longitude['geo_number'][1]\n",
    "    print('Do you want to enter your favorite books to start taking recommendations?')\n",
    "    user_preferences_2 = input('Yes/No: ')\n",
    "    if ((user_preferences_2.lower() == 'yes')|(user_preferences_2.lower() == 'y')):\n",
    "        ##Saving the ISBN of the books that the user wants to add to the system\n",
    "        isbn_list = [] \n",
    "        isbn_number = input('Please enter ISBN number of your book: ')\n",
    "        isbn_list.append(isbn_number)\n",
    "        q = input  (\"Do you want to write another ISBN number? Yes/No \")\n",
    "        q=q.lower()\n",
    "        while ((q == 'yes')|(q=='y')):\n",
    "            if (q.lower() =='y') | (q.lower()== 'yes'):\n",
    "                isbn = input (\"Please enter isbn number of the book: \")\n",
    "                isbn_list.append(isbn)\n",
    "                q = input  (\"Do you want to write another isbn number? \")\n",
    "\n",
    "        print(isbn_list)\n",
    "        new_user_df = pd.DataFrame()\n",
    "        all_languages = []\n",
    "        ## Web scraper scraps book metadata from bookfinder.com\n",
    "        for each_isbn in isbn_list:\n",
    "\n",
    "            base_url = 'https://www.bookfinder.com/search/?isbn='+each_isbn+'&mode=isbn&st=sr&ac=qr'\n",
    "            page = requests.get(base_url)\n",
    "            html = BeautifulSoup(page.content, \"html.parser\")\n",
    "            info_isbn_check = html.find_all(align = 'center')\n",
    "            text_isbn_check = (str(info_isbn_check))\n",
    "            regex_isbn_check = r\"Sorry, we found no matching results at this time\"\n",
    "\n",
    "            matches_isbn_check = re.finditer(regex_isbn_check, text_isbn_check, re.MULTILINE)\n",
    "\n",
    "            isbn_check = ''\n",
    "            for matchNum, match in enumerate(matches_isbn_check, start=1):\n",
    "\n",
    "                isbn_check= (\"{match}\".format(match = match.group()))\n",
    "                print(isbn_check)\n",
    "\n",
    "            if isbn_check == '':\n",
    "                print('Processing')\n",
    "                info = html.find_all(class_ = \"attributes\")\n",
    "                text = (str(info))\n",
    "\n",
    "                regex_name = r\"\\\"name\\\">[a-zA-z\\s\\W]*[a-zA-z\\s0-9()]*</span>\"\n",
    "                matches_name = re.finditer(regex_name, text, re.MULTILINE)\n",
    "\n",
    "                for matchNum, match in enumerate(matches_name, start=1):\n",
    "\n",
    "                    name_of_book =  (\"{match}\".format(match = match.group()))\n",
    "                    name_of_book=name_of_book.replace('\"name\">', '')\n",
    "                    name_of_book=name_of_book.replace('&amp;', '&')\n",
    "                    name_of_book=name_of_book.replace('</span>', '')\n",
    "\n",
    "\n",
    "                regex_author = r\"author\\\">[a-zA-Z\\.\\s\\,]*\"\n",
    "                matches_name = re.finditer(regex_author, text, re.MULTILINE)\n",
    "\n",
    "                for matchNum, match in enumerate(matches_name, start=1):\n",
    "\n",
    "                    name_of_author=(\"{match}\".format(match = match.group()))\n",
    "                    name_of_author=name_of_author.replace('author\\\">', '')\n",
    "                    name_of_author=name_of_author.replace('&amp;', '&')\n",
    "                    name_of_author=name_of_author.replace(',', ' ')\n",
    "\n",
    "                regex_publisher_and_year = r\"publisher\\\">[a-zA-Z\\s\\W]*[0-9]*\"\n",
    "                matches_publisher_and_year = re.finditer(regex_publisher_and_year, text, re.MULTILINE)\n",
    "\n",
    "                for matchNum, match in enumerate(matches_publisher_and_year, start=1):\n",
    "                    first_match=(\"{match}\".format(match = match.group()))\n",
    "                    first_match=first_match.replace('publisher\\\">','')\n",
    "                    first_match=first_match.replace('&amp;', '&')\n",
    "                    first_match= first_match.split(',')\n",
    "                    publisher = first_match[0]\n",
    "                    publication_year = first_match[1]\n",
    "                    publication_year=publication_year.replace(' ', '')\n",
    "\n",
    "                regex_language = r'lang=\\w*'\n",
    "                matches_language = re.finditer(regex_language, text, re.MULTILINE)\n",
    "                lang_list= []\n",
    "                for matchNum, match in enumerate(matches_language):\n",
    "                    language=(\"{match}\".format(match = match.group()))\n",
    "                    language = language.replace('lang=', '')\n",
    "                    lang_list.append(language)\n",
    "                language=lang_list[0]\n",
    "                all_languages.append(language)\n",
    "\n",
    "                regex_edution = r'bookformat\\\"/>[a-zA-Z]*'\n",
    "                matches_edution = re.finditer(regex_edution, text, re.MULTILINE)\n",
    "\n",
    "                for matchNum, match in enumerate(matches_edution):\n",
    "                    edution=(\"{match}\".format(match = match.group()))\n",
    "                    edution= edution.replace('bookformat\\\"/>', '')\n",
    "\n",
    "                info_desciription = html.find_all(class_ = \"description\")\n",
    "                info_desciription = (str(info_desciription))\n",
    "                if len(info_desciription) > 100:\n",
    "                    regex_desciription = r'itemprop=\\\"description\\\">.*\\.'\n",
    "                    matches_description = re.finditer(regex_desciription, info_desciription, re.MULTILINE)\n",
    "\n",
    "                    for matchNum, match in enumerate(matches_description, start=1):\n",
    "                        description=(\"{match}\".format(match = match.group()))\n",
    "                        description= description.replace('itemprop=\\\"description\">', '')\n",
    "                        description= description.replace('description\"><p>', '')\n",
    "                        description= description.replace('><p>', '')\n",
    "                        description= description.replace('<strong>', '')\n",
    "                        description= description.replace('<br/><br/>', '')\n",
    "                        description= description.replace('</strong></p><p>', '')\n",
    "                        description= description.replace('</p><p>', '')\n",
    "                        description= description.replace('</p', '')\n",
    "                        description= description.replace('<p>', '')\n",
    "                        description= description.replace('<br/>', '')\n",
    "                else:\n",
    "                    description = str('No description is available')\n",
    "\n",
    "\n",
    "                info_rating = html.find_all(class_ = \"rating\")\n",
    "                info_rating = (str(info_rating))\n",
    "\n",
    "                regex_rating = r'book-rating-average text-muted\\\">[0-9\\.]*'\n",
    "                matches_rating = re.finditer(regex_rating, info_rating, re.MULTILINE)\n",
    "\n",
    "                for matchNum, match in enumerate(matches_rating, start=1):\n",
    "                    rating=(\"{match}\".format(match = match.group()))\n",
    "                    rating= rating.replace('book-rating-average text-muted\\\">', '')\n",
    "\n",
    "\n",
    "                regex_voters = r'book-rating-provider text-muted\\\">[0-9\\s]*'\n",
    "                matches_voters = re.finditer(regex_voters, info_rating, re.MULTILINE)\n",
    "\n",
    "                for matchNum, match in enumerate(matches_voters, start=1):\n",
    "                    voters=(\"{match}\".format(match = match.group()))\n",
    "                    voters= voters.replace('book-rating-provider text-muted\\\">', '')\n",
    "                    voters= voters.replace(' ', '')\n",
    "\n",
    "                info_number_of_page = html.find_all(class_ = \"item-note\")\n",
    "                info_number_of_page = (str(info_number_of_page))\n",
    "\n",
    "                regex_number_of_pages = r'[0-9\\s]*pages'\n",
    "                matches_number_of_pages = re.finditer(regex_number_of_pages, info_number_of_page, re.MULTILINE)\n",
    "                matches_number_of_pages_list = []\n",
    "                for matchNum, match in enumerate(matches_number_of_pages, start=1):\n",
    "                    number_of_pages=(\"{match}\".format(match = match.group()))\n",
    "                    number_of_pages= number_of_pages.replace(' ', '')\n",
    "                    number_of_pages= number_of_pages.replace('pages', '')\n",
    "                    matches_number_of_pages_list.append(number_of_pages)\n",
    "\n",
    "                dict_of_book_info = {\"Name\": name_of_book,\"Authors\":name_of_author,'Publisher':publisher,\n",
    "                                   'ISBN':each_isbn, 'PublishYear':publication_year,'new_lang': language,'edution': edution,\n",
    "                                   'avg_rating':rating, 'voters':voters,'description':description}\n",
    "\n",
    "\n",
    "                new_user_df = new_user_df.append(dict_of_book_info,ignore_index = True)\n",
    "            else:\n",
    "                print(isbn_check,'Do you want to add book manually?')\n",
    "                manually_adder_decision = input('yes/no')\n",
    "                if manually_adder_decision == 'yes':\n",
    "                        name_of_book = input('Enter the name of the book')\n",
    "                        name_of_author = input('Enter the name of the author')\n",
    "                        isbn = input('Enter ISBN number of the book')\n",
    "                        rating = input('Enter the name of the Rating')\n",
    "                        publication_year = input('Enter the name of the publish_year')\n",
    "                        publisher = input('Enter the name of the publisher')\n",
    "                        language = input('Enter the language of the language')\n",
    "                        avg_rating = rating\n",
    "                        description = name_of_book\n",
    "                        dict_of_book_info = {\"Name\": name_of_book,\"Authors\":name_of_author,'ISBN':isbn,\n",
    "                                             'Publisher':publisher,'PublishYear':publication_year,'new_lang': language,\n",
    "                                             'avg_rating':rating,'description':description,}\n",
    "\n",
    "\n",
    "                        new_user_df = new_user_df.append(dict_of_book_info,ignore_index = True)\n",
    "\n",
    "            coords_user= (latitude,longitude)\n",
    "            df_books_and_geocodes = pd.read_csv(r'cleaned_and_scraped_real_data.csv')\n",
    "            df_books_and_geocodes['distance'] = ''\n",
    "            for index, each in enumerate(df_books_and_geocodes.Geocode):\n",
    "                df_books_and_geocodes['distance'][index] = geopy.distance.geodesic(coords_user, each).km\n",
    "\n",
    "            df_bookss = pd.concat([df_books_and_geocodes,new_user_df])\n",
    "            df_bookss.reset_index(drop=True,inplace=True)\n",
    "\n",
    "            tf = TfidfVectorizer(analyzer='word',\n",
    "                         ngram_range=(1, 2),\n",
    "                         min_df=0)\n",
    "\n",
    "            tfidf_matrix = tf.fit_transform(df_bookss['description'])\n",
    "\n",
    "            ## Calculate cosine similarity of the books descriprion\n",
    "            cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "            ## create dataframe with Name, Author, PublishYear, Publisher, new_lang, Description\n",
    "            titles = df_bookss[['Name','ISBN', 'Adress','new_lang','description','Geocode']]\n",
    "\n",
    "            ## Save the name of the books as an index\n",
    "            indices = pd.Series(df_bookss.index, index=df_bookss['ISBN'])\n",
    "            try:\n",
    "            # handle case in which book by same title is in dataset\n",
    "                idx = indices[each_isbn][0]\n",
    "            except IndexError:\n",
    "                idx = indices[each_isbn]\n",
    "\n",
    "            sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "            sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "            sim_scores = sim_scores[1:]\n",
    "            # There is an exact match between books with missing description data. \n",
    "            # These books have been removed from the dataset.\n",
    "            new_sim_scores= []\n",
    "            for each in sim_scores:\n",
    "                if each[1]!= 1:\n",
    "                    new_sim_scores.append(each)\n",
    "                    \n",
    "            book_indices = [i[0] for i in new_sim_scores]\n",
    "            book_sim_ratio = [i[1] for i in new_sim_scores]\n",
    "            book_sim_ratio_cols = {\"book_index\": book_indices,\"book_sim_ratio\":book_sim_ratio}\n",
    "            book_sim_ratio_df = new_user_df.append(book_sim_ratio_cols,ignore_index = True) \n",
    "            \n",
    "            df_bookss = df_bookss.rename(columns={'Unnamed: 0' :'indices' })\n",
    "            book_sim_ratio_df = pd.DataFrame.from_records(new_sim_scores, columns =['indices', 'sim_scores'])\n",
    "            \n",
    "            recommendation = df_bookss.merge(book_sim_ratio_df,how='inner',on='indices')\n",
    "            new_cols= ['Name', 'ISBN', 'Adress', 'new_lang', 'description', 'Geocode','sim_scores']\n",
    "            recommendation = recommendation [new_cols]\n",
    "            \n",
    "            language_based_list = pd.DataFrame()\n",
    "            for lang in all_languages:\n",
    "                a = recommendation[recommendation['new_lang'] == lang]\n",
    "                language_based_list = language_based_list.append(a)\n",
    "\n",
    "            coords_user= (latitude,longitude)\n",
    "            language_based_list['distance'] = ''\n",
    "            language_based_list = language_based_list.dropna(subset=['Geocode'])\n",
    "            language_based_list = language_based_list.reset_index(drop=True)\n",
    "            for index, each in enumerate(language_based_list.Geocode):\n",
    "                language_based_list['distance'][index]= geopy.distance.geodesic(coords_user, each).km\n",
    "\n",
    "            language_based_list_cols = ['Name','ISBN','new_lang','distance','Adress','sim_scores']\n",
    "            language_based_list = language_based_list[language_based_list_cols]\n",
    "            ## Removing the books which have no similarity from the user book\n",
    "            language_based_list = language_based_list[language_based_list.sim_scores>0]\n",
    "\n",
    "            print('The books given by user is written in',set(all_languages),'. So only',set(all_languages), 'books are shown in the recommendation')\n",
    "            print('1: Distance')\n",
    "            print('2: Similarity')\n",
    "\n",
    "            user_input = input('How do you want to sort your recommendations?')\n",
    "            if user_input == '1':\n",
    "                print('####### Nearest books ##########')\n",
    "                print(language_based_list.sort_values(by='distance',ascending= False).head(5))\n",
    "            else:\n",
    "                print('####### Most Similar books ##########')\n",
    "                print(language_based_list.sort_values(by='sim_scores',ascending= False).head(5))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "915a9306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your name:Ester\n",
      "Welcome Ester Do you want to share your current location with us to give you better recommendations?\n",
      "Yes/No? Yes\n",
      "Do you want to enter your favorite books to start taking recommendations?\n",
      "Yes/No: Yes\n",
      "Please enter ISBN number of your book: 9789403173207\n",
      "Do you want to write another ISBN number? Yes/No Yes\n",
      "Please enter isbn number of the book: 9781849832496\n",
      "Do you want to write another isbn number? \n",
      "['9789403173207', '9781849832496']\n",
      "Processing\n",
      "The books given by user is written in {'nl'} . So only {'nl'} books are shown in the recommendation\n",
      "1: Distance\n",
      "2: Similarity\n",
      "How do you want to sort your recommendations?2\n",
      "####### Most Similar books ##########\n",
      "                                                 Name           ISBN new_lang  \\\n",
      "0   Het Verloren Paradijs, Stukje 2 (1792) (Dutch ...  9781165335183       nl   \n",
      "3                            The Hunt for Red October  9789022994351       nl   \n",
      "4                            Mannen die vrouwen haten  9789056723088       nl   \n",
      "21                      Vincent Hamam (Dutch Edition)  9789077932049       nl   \n",
      "15                   Meester Jaap gaat nooit verloren  9789026990922       nl   \n",
      "\n",
      "    distance                             Adress  sim_scores  \n",
      "0   1.726005  Vossegatselaan 53 3583 RR Utrecht    0.023959  \n",
      "3   1.008229              Bankstraat 27 Utrecht    0.015911  \n",
      "4   1.008507              Bankstraat 27 Utrecht    0.013563  \n",
      "21  0.499227     tuinstraat 11, 3511 vc utrecht    0.012305  \n",
      "15  2.921695   Arnoldus Rotterdamstraat Utrecht    0.011515  \n",
      "Processing\n",
      "The books given by user is written in {'nl', 'en'} . So only {'nl', 'en'} books are shown in the recommendation\n",
      "1: Distance\n",
      "2: Similarity\n",
      "How do you want to sort your recommendations?1\n",
      "####### Nearest books ##########\n",
      "                                                  Name           ISBN  \\\n",
      "530  Swiss People of Austrian Descent: Austrian Exp...  9781156100479   \n",
      "528  Ravelstein (Penguin Great Books of the 20th Ce...  9780141001760   \n",
      "529                              The End of the Affair  9780099478447   \n",
      "451                                Eisenstaedt's Guide      670290815   \n",
      "443                               Die Schur. Erzählung     351838113X   \n",
      "\n",
      "    new_lang  distance                              Adress  sim_scores  \n",
      "530       en  4.072833              La Croixstraat utrecht    0.066319  \n",
      "528       en   3.81138  Adriaan Mulderstraat 56, Utrecht,     0.065737  \n",
      "529       en  3.811365  Adriaan Mulderstraat 56, Utrecht,     0.035678  \n",
      "451       nl  3.739926               Westfalen 58, Utrecht    0.047394  \n",
      "443       nl   3.56779        Filipijnen 7, 3524JJ Utrecht    0.004932  \n"
     ]
    }
   ],
   "source": [
    "recommendation_system()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
